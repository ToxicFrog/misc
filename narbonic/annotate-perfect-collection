#!/usr/bin/env bash
set -e
shopt -s lastpipe
cd "$(dirname "$0")"

### functions for toc files ###

# volume $name
# Set output name as given
VOLUME=""
function volume {
  VOLUME="$1"
  rm -rf "tmp/$VOLUME"
  mkdir -p "tmp/$VOLUME"
}

# Input settings.
SOURCE=""
function original { SOURCE="$1"; mkdir -p "tmp/$SOURCE"; }
DPI=150
function dpi { DPI="$1"; }

# stubbed out so that we can load the commentary index
function chapter {
  return 0
}

# page $name $title
# fetch the given page into the cache, if not already there
# then extract all commentary blocks from it and add them to the queue
CHEAD=0
function page {
  local name="$1"
  local title="$2"
  shift 2
  status "Commentary %04d \"%s\" (%s)" "$CHEAD" "$name" "$title"
  local out="tmp/html/$name"
  if [[ ! -f $out ]]; then
    status "Commentary %04d \"%s\" (%s) [download]" "$CHEAD" "$title" "$name"
    curl --retry 5 --silent "http://narbonic.com/comic/$name/" > "$out"
    chmod a-w "$out"
  else
    status "Commentary %04d \"%s\" (%s) [cached]" "$CHEAD" "$title" "$name"
  fi
  # at this point we have the page in cache, so extract commentary from it
  # unless we already have a *complete* commentary cache, in which case just
  # skip it
  [[ -f tmp/commentary/.complete ]] && return 0
  {
    # If we were passed extra arguments, extract those elements from the page,
    # in order. Otherwise, just scan the page for all "comic-strip-commentary-N"
    # blocks and extract those.
    if [[ $1 ]]; then printf '%s\n' "$@";
    else egrep -o 'comic-strip-commentary-[0-9]+' "$out" | sort -u
    fi
  } | while read id; do
    status "Commentary %04d \"%s\" (%s) [%s]" "$CHEAD" "$title" "$name" "$id"
    local div="$(wring html $out "#$id")"
    [[ ! $div ]] && continue
    local dst="tmp/commentary/$(printf %04d $CHEAD)"
    # we trim <br> tags here, because a lot of the commentary has hard linebreaks in it that
    # mess up the formatting quite badly...but this also breaks song and poem lyrics and whatnot.
    # We need to be smarter about this.
    #echo "$div" | sed -E 's,<br>,,g' > "$dst.html"
    echo "$div" > "$dst.html"
    ((++CHEAD))
    # fix up links in the comment fragment
    for link in $(egrep -o 'src="/wordpress/wp-content/uploads/[^"]+"' "$dst.html"); do
      local linkpath="$(echo "$link" | cut -d'"' -f2)"
      local basename="$(basename "$linkpath")"
      status "Commentary %04d \"%s\" (%s) [fixup %s]" "$CHEAD" "$title" "$name" "$(basename $link)"
      local file="$dst-$basename"
      [[ -f "$file" ]] || curl --retry 5 --silent "http://narbonic.com$linkpath" > "$file"
      sed -E -i "s;$link;src=\"$(basename "$file")\";g" "$dst.html"
    done

  done
}

function next-commentary-id {
  local CTAIL=$(cat tmp/commentary/.tail)
  if (( CTAIL == CHEAD )); then
    die "queue underflow reading commentary at $CTAIL"
  fi
  printf "%04d" "$CTAIL"
  echo $((++CTAIL)) > tmp/commentary/.tail
}

function sync {
  local n="$1"
  case "$n" in
    -*|+*)
      local tail=$(cat tmp/commentary/.tail)
      tail=$((tail+n))
      ;;
    *)
      tail=$n
      ;;
  esac
  echo "$tail" > tmp/commentary/.tail
}

function css {
  echo "$1" > tmp/style.css
}

# Extract a single page in raster format from the PDF.
# Takes as argument the page number, 0-indexed.
# Emits the basename of the extracted page, with extension.
RASTER_MODE=pdfimages
function raster-page {
  local page="$(printf page-%03d $1)"
  case $RASTER_MODE in
    pdfimages)
      pdfimages -all -f $(($1+1)) -l $(($1+1)) "$SOURCE" tmp/raster
      mv tmp/raster-000.jpg "tmp/$SOURCE/$page.jpg"
      echo "$page.jpg"
      ;;
    pdfimages-html)
      pdfimages -all -f $(($1+1)) -l $(($1+1)) "$SOURCE" "tmp/$SOURCE/$page"
      echo "$page"
      ;;
    imagemagick)
      convert \
        -define registry:temporary-path="$PWD/tmp/" \
        -density "$DPI" \
        "$SOURCE[$1]" \
        -colorspace gray \
        "tmp/$SOURCE/page-%03d.png"
      echo "$page.png"
      ;;
    imagemagick-aa)
      # sample at 2*DPI and then downscale
      convert \
        -define registry:temporary-path="$PWD/tmp/" \
        -density "$((DPI*2))" \
        "$SOURCE[$1]" \
        -colorspace gray \
        -scale '50%' \
        "tmp/$SOURCE/page-%03d.png"
      echo "$page.png"
      ;;
    *)
      die "unknown raster mode $RASTER_MODE"
      ;;
  esac
}

# copy $start [$end]
# copy the given pages, as is, from the input PDF to the output
function copy {
  local first="$1"
  if [[ $2 ]]; then
    local last="$2"
  else
    local last="$first"
  fi
  status "page %03d-%03d: copying" "$first" "$last"
  # The index file uses 0-indexing. pdfseparate uses 1-indexing. We standardize
  # on 0-indexing at the interfaces and adjust here.
  pdfseparate -f $((first+1)) -l $((last+1)) \
    "$SOURCE" "tmp/$VOLUME/page-%03d.pdf"
}

# whole $start [$end]
# copy the given pages, and for each one, pull commentary from the queue and
# insert it between the main page content and the page number.
function whole {
  local start=$1
  if [[ $2 ]]; then
    local end=$2; shift 2
  else
    local end=$start; shift 1
  fi
  for i in $(seq $start $end); do
    local page="$(raster-page $i)"
    status "$page: annotating"
    if [[ $RASTER_MODE == pdfimages-html ]]; then
      add-commentary-multi-image "tmp/$SOURCE/$page" LAST
    else
      add-commentary "tmp/$SOURCE/$page" \
        $(find-splits "tmp/$SOURCE/$page" "$@" | sort -g | tail -n1)
    fi
  done
}

# split $start [$end]
# scan the given pages for distinct comic strips and split them apart; then, for
# each found strip, top to bottom, pull commentary from the queue and append it.
# finally, stitch the page back together and add it to the output.
function split {
  local start=$1
  if [[ $2 ]]; then
    local end=$2; shift 2
  else
    local end=$start; shift 1
  fi
  for i in $(seq $start $end); do
    local page="$(raster-page $i)"
    status "$page: splitting and annotating"
    if [[ $RASTER_MODE == pdfimages-html ]]; then
      add-commentary-multi-image "tmp/$SOURCE/$page" ALL
    else
      add-commentary "tmp/$SOURCE/$page" \
        $(find-splits "tmp/$SOURCE/$page" "$@" | sort -g)
    fi
  done
}

# split-at $page $split $split...
# split the given page (one only) at the given lines. Do not attempt to
# autodetect split points at all. Use only for pages where split detection
# fails badly.
function split-at {
  local page="$(raster-page $1)"
  shift
  status "$page: splitting and annotating"
  if [[ RASTER_MODE == pdfimages-html ]]; then die "split-at not supported in pdfimages-html mode"; fi
  add-commentary "tmp/$SOURCE/$page" "$@"
}

# endvolume
# finalize the volume by packing it into a PDF or a CBZ
function endvolume {
  if [[ ! $VOLUME ]]; then die "endvolume without matching volume"; fi
  status "Packing $VOLUME.pdf"
  (cd "tmp/$VOLUME" && pdfunite *.pdf "../../out/$VOLUME.pdf")
  status "Packed out/$VOLUME.pdf\\n"
  VOLUME=""
}


#### supporting functions ####


# find-splits $img
# scan it for horizontal split points, output the Y coordinate of each split
# on stdout
function find-splits {
  local img="$1"; shift
  if [[ $1 ]]; then printf "%s\n" "$@"; fi
  convert "$img" -resize '1x!' txt: | lua -e '
    local sof,eof
    local didsplit = false
    local depth = 0
    for line in io.lines() do
      --local y,colour = line:match("^0,(%d+):.*gray%(255%)$")
      local y,colour = line:match("^0,(%d+):.*#FFFFFF")
      if y then
        depth = 0
        sof = sof or tonumber(y)
        eof = tonumber(y)
        --io.stderr:write("sof: "..y.."\n")
      elseif not y then
        depth = depth+1
        if sof and eof
          -- ugly heuristics
          and depth > 2
          and sof > 200
          and eof - sof >= 8 then
          --io.stderr:write("split: "..sof.."-"..eof.."\n")
          print(math.floor(sof + (eof-sof)/8))
          didsplit = true
        end
        if depth > 2 then
          sof,eof = nil
        end
      end
    end
    -- hack so that if we found NO splits, which usually means a single-page
    -- comic so large that it obscures the page number, we forcibly emit one
    -- at the very end
    if not didsplit and sof and eof then
      print(math.floor((sof+eof)/2))
    end'
}

function find-margins {
  local LM=$(convert "$1" -resize '!x1' txt: | egrep -v '^#' | fgrep -v 'gray(255)' | head -n1 | cut -d, -f1)
  local RM=$(convert "$1" -resize '!x1' txt: | egrep -v '^#' | fgrep -v 'gray(255)' | tail -n1 | cut -d, -f1)
  printf '%d %d\n' $LM $RM
}

# TODO we get the width on $2; wrap the whole thing in a div or something that
# has the necessary width or margins or something
function html-commentary {
  cat "tmp/commentary/$1.html" \
  | sed -E 's,img src=",img src="../../tmp/commentary/,g'
}

# add-commentary IN SPLITS...
# add commentary to IN and write the resulting image to OUT
# n.b. IN and OUT probably have directory separators in them; handle with care
# Redesign: rather than using image processing for all of this:
# - do a series of crops to slice the image into subimages at the given lines
# - output HTML combining the images and the commentary concatenated
# - use wkhtmltopdf to write output.pdf
function add-commentary {
  if [[ $RASTER_MODE == pdfimages-html ]]; then
    add-commentary-multi-image "$@"
    return 0
  fi

  local input="$1"
  local page="$(basename "$input")"
  local output="tmp/$VOLUME/${page%.*}.html"
  local ext="${page##*.}"
  shift

  local old_y=0
  echo -n > "$output"
  for Y in "$@"; do
    cid=$(next-commentary-id)
    status "$page: insert commentary %s @ %d-%d" $cid $old_y $Y
    local slice="${input}-${old_y}-$Y.$ext"
    # This requires some explanation.
    # We want to trim off the sides to eliminate margin whitespace as much as possible,
    # and then re-add the whitespace as actual page margins when generating the PDF.
    # So, we add a pure white border around the image, then put a magenta stripe down the
    # right side to protect the right, top, and bottom before we trim, causing it to trim
    # only the left side; then we do the same thing to trim only the right, then remove the white border.
    # Finally we cut out the slice requested and save it. We don't need to adjust the slice
    # heights because only the width of the image has changed, not the height.
    [[ -f $slice ]] || convert "$input" \
      -bordercolor White -border 1x1 -fuzz "1%" -background Magenta \
      -gravity East -splice 1x0 -trim -chop 1x0 \
      -gravity West -splice 1x0 -trim -chop 1x0 \
      -shave 0x1 -gravity Northwest \
      -crop x$((Y-old_y))+0+$((old_y)) +repage \
      "$slice"
    printf '<img class="strip" src="../../%s">\n' "$slice" >> "$output"
    html-commentary $cid $width >> "$output"
    old_y=$Y
  done
  status "$page: slice footer"
  local slice="${input}-${old_y}-EOF.$ext"
  [[ -f $slice ]] || convert "$input" \
    -bordercolor White -border 1x1 -fuzz "1%" -background Magenta \
    -gravity East -splice 1x0 -trim -chop 1x0 \
    -gravity West -splice 1x0 -trim -chop 1x0 \
    -shave 0x1 -gravity Northwest \
    -crop +0+$((old_y)) +repage \
    "$slice"
  printf '<img src="../../%s">\n' "$slice" >> "$output"

  status "$page: render commentary"
  wkhtmltopdf --enable-local-file-access --quiet \
    --user-style-sheet tmp/style.css \
    -B 0 -T 0 -L 0 -R 0 \
    --page-width 20cm \
    --page-height 400cm \
    "$output" "${output%.*}.pdf"
  pdfcrop --margins "20 0 20 0" \
    "${output%.*}.pdf" "${output%.*}.pdf" >/dev/null
}

# add-commentary-multi-image IN <ALL|LAST>
# An alternate version of add-commentary for pdfimages-html mode.
# Takes a page *prefix* as $1 and
function add-commentary-multi-image {
  local input="$1"
  local inputdir="$(dirname "$input")"
  local page="$(basename "$input")"
  local output="tmp/$VOLUME/$page.html"
  shift

  local width=0
  echo '<!-- MEDIA SIZE 24x400cm -->' > "$output"
  # experimental: reverse extracted image order because pdfimages spits them
  # out bottom to top
  for img in $(cd "$inputdir" && printf '%s\n' "$page-"* | tac); do
    printf '<img align="center" src="../../%s/%s"><br/>\n' "$inputdir" "$img" >> "$output"
    local new_width=$(identify "$inputdir/$img" | egrep -o '[0-9]+x[0-9]+' | head -n1 | cut -dx -f1)
    if (( new_width > width )); then
      width=$new_width
    fi
    if [[ $1 == ALL ]]; then
      cid=$(next-commentary-id)
      status "$page: insert commentary %s after %s" $cid $img
      html-commentary $cid >> "$output"
    fi
  done
  if [[ $1 == LAST ]]; then
    cid=$(next-commentary-id)
    status "$page: insert commentary %s after %s" $cid $img
    html-commentary $cid >> "$output"
  fi
  printf '<div align="center"><big>%d</big></div>\n' $(( 10#${page##page-} )) >> "$output"
  status "$page: render commentary"
  # We use htmldoc rather than wkhtmltopdf for the second volume; it is harder
  # to use since it doesn't support CSS, but wkhtmltopdf will convert all the
  # PNG images to JPEG and make the file size 5-8x larger.
  htmldoc --webpage --continuous --quiet \
    --footer . \
    --browserwidth $width \
    --fontsize 16 \
    -f "${output%.*}.pdf" "$output"
  pdfcrop --margins "20 50 20 50" \
    "${output%.*}.pdf" "${output%.*}.pdf" >/dev/null
}

# Now the actual machinery of the program

set -e
shopt -s lastpipe

function main {
  checkdeps \
    wkhtmltopdf \
    convert identify \
    pdfimages pdfseparate pdfunite pdfcrop \
    wring \
    gs \
    curl zip fgrep egrep cut sed
  mkdir -p tmp/{commentary,html} out
  # Load commentary
  source perfect-collection-commentary.toc
  echo 0 > tmp/commentary/.tail
  if [[ -f tmp/commentary/.complete ]]; then
    CHEAD=$(ls tmp/commentary/*.html | wc -l)
    ((++CHEAD))
  else
    touch tmp/commentary/.complete
  fi
  status "Done initializing commentary with $CHEAD entries; building images next.\\n"
  # Generate the actual volumes.
  source perfect-collection.toc
}

function status {
  local fmt="$1"; shift
  printf '\r\x1B[2K'"$fmt" "$@" >&2
}

if [[ $DEBUG ]]; then
  function status {
    local fmt="$1"; shift
    printf "$fmt\n" "$@" >&2
  }
fi

function checkdeps {
  local missing=""
  for command in "$@"; do
    if ! type "$command" 2>/dev/null >/dev/null; then
      missing+=" $command"
    fi
  done
  if [[ "$missing" ]]; then
    echo "You are missing the following commands:$missing" >&2
    echo "Please install them and try again." >&2
    exit 1
  fi
}

function die {
  echo "$@" >&2
  exit 1
}

main
